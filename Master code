import tensorflow as tf
from tensorflow import keras
import numpy as np
import matplotlib.pyplot as plt


########
# https://github.com/tensorflow/tensorflow/issues/33285
import requests
requests.packages.urllib3.disable_warnings()
import ssl

try:
    _create_unverified_https_context = ssl._create_unverified_context
except AttributeError:
    # Legacy Python that doesn't verify HTTPS certificates by default
    pass
else:
    # Handle target environment that doesn't support HTTPS verification
    ssl._create_default_https_context = _create_unverified_https_context
########

data = keras.datasets.fashion_mnist

# When doing this with my own data, have to format
# to make it load into this style with for loops, ...
# This is a numpy array
(train_images, train_labels), (test_images, test_labels) = data.load_data()

class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

# To show an image using matlib
# cmap makes it binary
# plt.imshow(train_images[7], cmap=plt.cm.binary)
# plt.show()

# Each image is composed of an array of 28x28 pixels with values [0,255] like colours
# We need to make them [0,1]
train_images = train_images/255.0
test_images = test_images/255.0

# print(train_images[7])

# # Labels: There are 10 labels that are preprogrammed in as what the image ACTUALLY is
# print(train_labels[0])


#######################################################################################

# As input, we can't give it [[], [], ... , []] (x28) (28 arrays of 28 values)
# Instead we give it one array of 784 digits (nodes)


# 1 hidden layer is usually enough. It should be filled with (inputNodes+outputNodes)/2 nodes
# Others say 15-20% of the input
# We'll use 128 here



# Output layer is [0,9] representing each class, each [0,1].

# Sequential means a bunch of layers given in order
model = keras.Sequential([
	# Have to flatten data into one info per node
	keras.layers.Flatten(input_shape=(28,28)),
	# 'fully connected layer' = dense
	# Rectified linear unit. Arbitrary, but this one is quite quick
	keras.layers.Dense(128, activation="relu"),
	# softmax picks value so that the output is a percentage of what it thinks
	# (all sum to one)
	keras.layers.Dense(10, activation="softmax")
	])

# Paramaters
# Accuracy means that we want to minimise the loss function (of which there are many)
# Would play around with a couple of different of all 3 to see what improves 
# performance (usually not metrics)
model.compile(optimizer="adam", loss="sparse_categorical_crossentropy", metrics=["accuracy"])



# Epochs means the amount of times the same image is shown to the model
# Seeing 10 shirts then 10 pants is more biased than interchanging each by chance. 
model.fit(train_images, train_labels, epochs=5)

### So this one is for evaluation
# test_loss, test_acc = model.evaluate(test_images, test_labels)
# # Got 87%
# print("This is the output: ", test_acc)


### Can do individual predictions now
# Takes in a list of the inputs and then predicts for each element
prediction = model.predict(test_images)
# # Prints the probability of being that class i.e. 10 probabilities. 
# print(prediction[0])

# # Make it print the class of the most likely one:
# print(class_names[argmax(prediction[0])])

# So make a loop that prints the prediction and the correct answer:
print("x Answer,			Correct,")
for x in range(15):
	print(x, class_names[np.argmax(prediction[x])],			class_names[test_labels[x]])

# Alternatively with a plot:
for x in range(10):
	plt.grid(False)
	plt.imshow(test_images[x], cmap=plt.cm.binary)
	plt.xlabel("Actual: " + class_names[test_labels[x]])
	plt.title("Prediction " + class_names[np.argmax(prediction[x])])
	plt.show()
